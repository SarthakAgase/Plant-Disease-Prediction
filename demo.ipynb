{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarth\\AppData\\Local\\Temp\\ipykernel_18872\\3288513875.py:48: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['label'] = df['label'].replace({'Potato___healthy':0,\n",
      "100%|██████████| 2152/2152 [00:02<00:00, 804.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train : (1721, 150, 150, 3)\n",
      "Shape of X_test : (431, 150, 150, 3)\n",
      "Shape of y_train : (1721,)\n",
      "Shape of y_test : (431,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_203']. Received: the structure of inputs=*\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 4s/step - accuracy: 0.4530 - loss: 1.9344 - val_accuracy: 0.6435 - val_loss: 0.7608\n",
      "Epoch 2/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.7194 - loss: 0.6161 - val_accuracy: 0.8261 - val_loss: 0.4904\n",
      "Epoch 3/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.8951 - loss: 0.3138 - val_accuracy: 0.8870 - val_loss: 0.2837\n",
      "Epoch 4/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.8983 - loss: 0.2688 - val_accuracy: 0.8841 - val_loss: 0.3042\n",
      "Epoch 5/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.9255 - loss: 0.1673 - val_accuracy: 0.8957 - val_loss: 0.3212\n",
      "Epoch 6/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.9501 - loss: 0.1402 - val_accuracy: 0.9362 - val_loss: 0.1993\n",
      "Epoch 7/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.9626 - loss: 0.0913 - val_accuracy: 0.9304 - val_loss: 0.1860\n",
      "Epoch 8/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.9696 - loss: 0.0799 - val_accuracy: 0.9420 - val_loss: 0.1596\n",
      "Epoch 9/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4s/step - accuracy: 0.9769 - loss: 0.0742 - val_accuracy: 0.9304 - val_loss: 0.3108\n",
      "Epoch 10/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4s/step - accuracy: 0.9838 - loss: 0.0423 - val_accuracy: 0.9420 - val_loss: 0.1602\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Conv2D, MaxPooling2D , BatchNormalization ,Dropout ,Flatten , Dense , Input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "dataDir = 'datasets\\Potato'\n",
    "selectedClasses = ['Potato___healthy',\n",
    "                   'Potato___Early_blight',\n",
    "                   'Potato___Late_blight',\n",
    "                   ]\n",
    "\n",
    "imgPaths = []\n",
    "labels = []\n",
    "for className in os.listdir(dataDir):\n",
    "    if className in selectedClasses :                  # Select you classes above\n",
    "        classPath = os.path.join(dataDir,className)\n",
    "        for img in os.listdir(classPath):\n",
    "            imgPath = os.path.join(classPath,img)\n",
    "            imgPaths.append(imgPath)\n",
    "            labels.append(className)\n",
    "            \n",
    "# Convert the 2 lists to dataframe to easy use \n",
    "df = pd.DataFrame({\n",
    "    'imgPath':imgPaths,\n",
    "    'label':labels\n",
    "})\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)            # Shuffle\n",
    "\n",
    "df['label'] = df['label'].replace({'Potato___healthy':0,\n",
    "                                    'Potato___Early_blight':1,\n",
    "                                    'Potato___Late_blight':2,\n",
    "                                    }).astype(int)\n",
    "\n",
    "IMG_SIZE = (150,150)   # to free some resources and reduce the execution time\n",
    "imgs = []\n",
    "for imgPath in tqdm(df['imgPath'], total=len(df)):\n",
    "    img = cv2.imread(imgPath)\n",
    "    img = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    imgs.append(img)\n",
    "\n",
    "# convert them to numpy array to we can split them \n",
    "images = np.array(imgs)\n",
    "labels = np.array(df['label'])\n",
    "\n",
    "images = images / 255.0         # normalize from 0 --> 255 to 0 --> 1  to reduce the execution time \n",
    "\n",
    "# Spliting \n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42 ,shuffle=True)\n",
    "\n",
    "print(f'Shape of X_train : {X_train.shape}')\n",
    "print(f'Shape of X_test : {X_test.shape}')\n",
    "print(f'Shape of y_train : {y_train.shape}')\n",
    "print(f'Shape of y_test : {y_test.shape}')\n",
    "\n",
    "custom_input = Input(shape=(150, 150, 3))           # To customize the input shape of PreTrained model  \n",
    "\n",
    "with tf.device('/GPU:0'):          # to use GPU\n",
    "    Model = Sequential([\n",
    "\n",
    "        VGG16(weights='imagenet', include_top=False, input_tensor=custom_input),\n",
    "        \n",
    "        Flatten(),                                     # because we ignore the flatten and dense layers when include_top = False \n",
    "        \n",
    "        Dense(128,activation='relu'),\n",
    "        \n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(3 ,activation='softmax')\n",
    "    ])\n",
    "\n",
    "VGG16Layers = Model.layers[0]\n",
    "for layer in VGG16Layers.layers[1:-3]:           # freez all layers except the first and last 3 layers, we will make them trainable (weghts changes with training)\n",
    "    layer.trainable = False\n",
    "\n",
    "Model.compile(optimizer='adam',loss='sparse_categorical_crossentropy' ,metrics=['accuracy'])\n",
    "\n",
    "history = Model.fit(X_train,y_train,\n",
    "                         validation_split = 0.2 , #validation_data=(X_test,y_test),\n",
    "                         epochs=10,\n",
    "                         batch_size=100, \n",
    "                         verbose=1,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                                            patience=5,\n",
    "                                            monitor='val_accuracy',\n",
    "                                            restore_best_weights=True)])\n",
    "\n",
    "y_pred = Model.predict(X_test)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "test_result = [np.argmax(x) for x in y_pred]\n",
    "\n",
    "CM = confusion_matrix(y_test, test_result)\n",
    "sns.heatmap(CM, center = True,cmap='summer',annot=True ,fmt='.5g')\n",
    "plt.show()\n",
    "\n",
    "ClassificationReport = classification_report(y_test,test_result)\n",
    "print('Classification Report is : \\n', ClassificationReport )\n",
    "\n",
    "Model.save('Potato.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potato.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "[[1.4737602e-16 1.0000000e+00 1.8552462e-11]]\n",
      "[1]\n",
      "Potato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "def predictDisease(imgPath,crop_name,crop_array):\n",
    "    test_df = pd.DataFrame({\n",
    "        'imgPath':imgPath,\n",
    "    }, index=[0])\n",
    "\n",
    "    IMG_SIZE = (150,150)   # to free some resources and reduce the execution time\n",
    "    imgs = []\n",
    "    for imgPath in tqdm(test_df['imgPath'], total=len(test_df)):\n",
    "        img = cv2.imread(imgPath)\n",
    "        img = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        imgs.append(img)\n",
    "\n",
    "    images = np.array(imgs)\n",
    "    images = images / 255.0         # normalize from 0 --> 255 to 0 --> 1  to reduce the execution time \n",
    "\n",
    "    # new_model = tf.keras.models.load_model('pepper_bell_model.keras')\n",
    "    print(f'{crop_name}.keras')\n",
    "    new_model = tf.keras.models.load_model(f'{crop_name}.keras')\n",
    "\n",
    "    test_result = new_model.predict(images)\n",
    "    print(test_result)\n",
    "    test_result = [np.argmax(x) for x in test_result]\n",
    "    print(test_result)\n",
    "\n",
    "    print(crop_array[test_result[0]])\n",
    "\n",
    "corn = [\"Corn__healthy\",\"Corn__blight\", \"Corn__common_rust\",\"Corn__gray_leaf_spot\"]\n",
    "pepper_bell = [\"Pepper__bell___healthy\", \"Pepper__bell___Bacterial_spot\"]\n",
    "potato = [\"Potato___healthy\", \"Potato___Early_blight\",\"Potato___Late_blight\"]\n",
    "tomato = [\"Tomato_healthy\", \"Tomato__Target_Spot\",\"Tomato__Tomato_mosaic_virus\",\"Tomato__Tomato_YellowLeaf__Curl_Virus\",\"Tomato_Bacterial_spot\"]\n",
    "\n",
    "# predictDisease(\"demo\\Corn__gray_leaf_spot_1.JPG\", \"Corn\", corn)\n",
    "# predictDisease(\"demo\\Pepper__bell___Bacterial_spot_3.JPG\", \"Pepper Bell\", pepper_bell)\n",
    "predictDisease(\"demo\\Potato___Early_blight_3.JPG\", \"potato\", potato)\n",
    "# predictDisease(\"demo\\Tomato_Bacterial_spot_3.JPG\", \"Tomato\", tomato)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
